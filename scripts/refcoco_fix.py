#!/usr/bin/env python3
"""
refcoco_fix.py

å®Œæ•´çš„ RefCOCO æ•¸æ“šé¡å‹ä¿®å¾©è§£æ±ºæ–¹æ¡ˆ
é‹è¡Œæ­¤è…³æœ¬å°‡è‡ªå‹•ä¿®å¾© train_refcoco_improved.py ä¸­çš„æ•¸æ“šé¡å‹éŒ¯èª¤

ä½¿ç”¨æ–¹æ³•ï¼š
python refcoco_fix.py
"""

import os
import shutil
import re
from pathlib import Path
from datetime import datetime


def create_backup(script_path):
    """å‰µå»ºè…³æœ¬å‚™ä»½"""
    if not script_path.exists():
        print(f"âŒ è…³æœ¬ä¸å­˜åœ¨: {script_path}")
        return None
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_path = script_path.with_suffix(f'.backup_{timestamp}.py')
    shutil.copy2(script_path, backup_path)
    print(f"âœ… å·²å‰µå»ºå‚™ä»½: {backup_path}")
    return backup_path


def get_complete_patch_code():
    """è¿”å›å®Œæ•´çš„ä¿®å¾©ä»£ç¢¼"""
    return '''
# ================== RefCOCO æ•¸æ“šé¡å‹ä¿®å¾©è£œä¸ ==================
# è‡ªå‹•æ·»åŠ  - ä¿®å¾© 'invalid data type str' éŒ¯èª¤

import torch
import numpy as np
from typing import Any, Union, List, Dict
import warnings
warnings.filterwarnings("ignore", category=UserWarning)

def safe_convert_to_tensor(data: Any, dtype: torch.dtype = torch.float32, expected_shape: tuple = None) -> torch.Tensor:
    """
    å®‰å…¨åœ°å°‡ä»»ä½•æ•¸æ“šè½‰æ›ç‚ºPyTorchå¼µé‡
    """
    try:
        if data is None:
            return torch.zeros(expected_shape or (1,), dtype=dtype)
        
        # è™•ç†å­—ç¬¦ä¸²é¡å‹
        if isinstance(data, str):
            data = data.strip()
            
            # è™•ç† bbox æ ¼å¼ "[0.1, 0.2, 0.8, 0.9]"
            if data.startswith('[') and data.endswith(']'):
                try:
                    cleaned = data.strip('[]').replace(' ', '')
                    if cleaned:
                        values = [float(x) for x in cleaned.split(',')]
                        tensor = torch.tensor(values, dtype=dtype)
                        if expected_shape and len(expected_shape) == 1 and tensor.numel() != expected_shape[0]:
                            if tensor.numel() > expected_shape[0]:
                                tensor = tensor[:expected_shape[0]]
                            else:
                                padded = torch.zeros(expected_shape[0], dtype=dtype)
                                padded[:tensor.numel()] = tensor
                                tensor = padded
                        return tensor
                    else:
                        return torch.zeros(expected_shape or (4,), dtype=dtype)
                except Exception:
                    return torch.zeros(expected_shape or (4,), dtype=dtype)
            
            # è™•ç†é€—è™Ÿåˆ†éš” "0.1,0.2,0.8,0.9"
            elif ',' in data:
                try:
                    values = [float(x.strip()) for x in data.split(',')]
                    return torch.tensor(values, dtype=dtype)
                except Exception:
                    return torch.zeros(expected_shape or (len(data.split(',')),), dtype=dtype)
            
            # å–®å€‹æ•¸å€¼
            else:
                try:
                    if data.replace('.', '').replace('-', '').replace('e', '').replace('E', '').replace('+', '').isdigit():
                        return torch.tensor(float(data), dtype=dtype)
                    else:
                        return torch.zeros(expected_shape or (1,), dtype=dtype)
                except Exception:
                    return torch.zeros(expected_shape or (1,), dtype=dtype)
        
        # è™•ç†åˆ—è¡¨/å…ƒçµ„
        elif isinstance(data, (list, tuple)):
            try:
                numeric_data = []
                for item in data:
                    if isinstance(item, str):
                        try:
                            # å˜—è©¦è§£æå­—ç¬¦ä¸²æ•¸å­—
                            if item.strip():
                                numeric_data.append(float(item))
                            else:
                                numeric_data.append(0.0)
                        except ValueError:
                            numeric_data.append(0.0)
                    elif isinstance(item, (int, float, bool)):
                        numeric_data.append(float(item))
                    else:
                        numeric_data.append(0.0)
                
                tensor = torch.tensor(numeric_data, dtype=dtype)
                
                # èª¿æ•´å½¢ç‹€
                if expected_shape and len(expected_shape) == 1:
                    if tensor.numel() > expected_shape[0]:
                        tensor = tensor[:expected_shape[0]]
                    elif tensor.numel() < expected_shape[0]:
                        padded = torch.zeros(expected_shape[0], dtype=dtype)
                        padded[:tensor.numel()] = tensor
                        tensor = padded
                
                return tensor
            except Exception:
                return torch.zeros(expected_shape or (len(data),), dtype=dtype)
        
        # è™•ç† numpy æ•¸çµ„
        elif isinstance(data, np.ndarray):
            try:
                if dtype == torch.float32:
                    return torch.from_numpy(data.astype(np.float32))
                elif dtype == torch.long:
                    return torch.from_numpy(data.astype(np.int64))
                else:
                    return torch.from_numpy(data).to(dtype)
            except Exception:
                return torch.zeros(expected_shape or data.shape, dtype=dtype)
        
        # å·²ç¶“æ˜¯å¼µé‡
        elif isinstance(data, torch.Tensor):
            try:
                # æª¢æŸ¥æ˜¯å¦æ˜¯å°è±¡é¡å‹å¼µé‡
                if str(data.dtype) == 'object':
                    # å˜—è©¦å¾å°è±¡å¼µé‡ä¸­æå–æ•¸æ“š
                    try:
                        if hasattr(data, 'tolist'):
                            extracted_data = data.tolist()
                        else:
                            extracted_data = [item for item in data]
                        return safe_convert_to_tensor(extracted_data, dtype, expected_shape)
                    except Exception:
                        return torch.zeros(expected_shape or data.shape, dtype=dtype)
                else:
                    tensor = data.to(dtype)
                    if expected_shape and tensor.shape != expected_shape and tensor.numel() == np.prod(expected_shape):
                        tensor = tensor.view(expected_shape)
                    return tensor
            except Exception:
                return torch.zeros(expected_shape or data.shape, dtype=dtype)
        
        # æ•¸å€¼é¡å‹
        elif isinstance(data, (int, float, bool, np.number)):
            return torch.tensor(float(data), dtype=dtype)
        
        # æœªçŸ¥é¡å‹
        else:
            print(f"Warning: Unknown data type {type(data)}: {data}")
            return torch.zeros(expected_shape or (1,), dtype=dtype)
            
    except Exception as e:
        print(f"Error converting data {data}: {e}")
        return torch.zeros(expected_shape or (1,), dtype=dtype)


def fix_batch_data_types(batch):
    """
    ä¿®å¾© batch ä¸­çš„æ•¸æ“šé¡å‹å•é¡Œ - æ ¸å¿ƒä¿®å¾©å‡½æ•¸
    é€™å€‹å‡½æ•¸è§£æ±ºäº† 'invalid data type str' éŒ¯èª¤
    """
    if not isinstance(batch, dict):
        return batch
    
    fixed_batch = {}
    
    for key, value in batch.items():
        try:
            if key == 'bbox':
                # è™•ç†é‚Šç•Œæ¡†æ•¸æ“š
                if isinstance(value, torch.Tensor):
                    if str(value.dtype) == 'object':
                        # å°è±¡é¡å‹å¼µé‡ï¼Œéœ€è¦ç‰¹åˆ¥è™•ç†
                        try:
                            bbox_list = []
                            for i in range(value.size(0)):
                                bbox_item = value[i]
                                if hasattr(bbox_item, 'item'):
                                    bbox_data = bbox_item.item()
                                else:
                                    bbox_data = bbox_item
                                
                                # è½‰æ›æ¯å€‹ bbox
                                fixed_bbox = safe_convert_to_tensor(bbox_data, torch.float32, (4,))
                                bbox_list.append(fixed_bbox.unsqueeze(0))
                            
                            if bbox_list:
                                fixed_batch[key] = torch.cat(bbox_list, dim=0)
                            else:
                                fixed_batch[key] = torch.zeros((1, 4), dtype=torch.float32)
                        except Exception as e:
                            print(f"Error processing bbox object tensor: {e}")
                            batch_size = value.size(0) if value.dim() > 0 else 1
                            fixed_batch[key] = torch.zeros((batch_size, 4), dtype=torch.float32)
                    else:
                        # æ­£å¸¸å¼µé‡ï¼Œç¢ºä¿æ˜¯ float32
                        fixed_batch[key] = value.float()
                elif isinstance(value, (list, tuple)):
                    # åˆ—è¡¨å½¢å¼çš„ bbox
                    bbox_list = []
                    for bbox_item in value:
                        fixed_bbox = safe_convert_to_tensor(bbox_item, torch.float32, (4,))
                        bbox_list.append(fixed_bbox.unsqueeze(0))
                    
                    if bbox_list:
                        fixed_batch[key] = torch.cat(bbox_list, dim=0)
                    else:
                        fixed_batch[key] = torch.zeros((len(value), 4), dtype=torch.float32)
                else:
                    # å…¶ä»–æ ¼å¼
                    fixed_batch[key] = safe_convert_to_tensor(value, torch.float32)
            
            elif key in ['input_ids', 'attention_mask', 'labels']:
                # è™•ç†æ–‡æœ¬ç›¸é—œå¼µé‡
                if isinstance(value, torch.Tensor):
                    if str(value.dtype) == 'object':
                        try:
                            text_list = []
                            for i in range(value.size(0)):
                                text_item = value[i]
                                if hasattr(text_item, 'item'):
                                    text_data = text_item.item()
                                else:
                                    text_data = text_item
                                
                                fixed_text = safe_convert_to_tensor(text_data, torch.long)
                                text_list.append(fixed_text.unsqueeze(0))
                            
                            if text_list:
                                # æ‰¾åˆ°æœ€å¤§é•·åº¦ä¸¦å¡«å……
                                max_len = max(t.size(1) for t in text_list)
                                padded_list = []
                                for t in text_list:
                                    if t.size(1) < max_len:
                                        pad_size = max_len - t.size(1)
                                        padding = torch.zeros((1, pad_size), dtype=torch.long)
                                        if key == 'labels':
                                            padding.fill_(-100)  # æ¨™ç±¤çš„å¡«å……å€¼
                                        t = torch.cat([t, padding], dim=1)
                                    padded_list.append(t)
                                
                                fixed_batch[key] = torch.cat(padded_list, dim=0)
                            else:
                                fixed_batch[key] = torch.zeros((1, 512), dtype=torch.long)
                        except Exception as e:
                            print(f"Error processing {key} object tensor: {e}")
                            fixed_batch[key] = torch.zeros_like(value, dtype=torch.long)
                    else:
                        fixed_batch[key] = value.long()
                else:
                    fixed_batch[key] = safe_convert_to_tensor(value, torch.long)
            
            elif key == 'pixel_values':
                # è™•ç†åœ–åƒå¼µé‡
                if isinstance(value, torch.Tensor):
                    if str(value.dtype) == 'object':
                        try:
                            # å°è±¡é¡å‹çš„åœ–åƒå¼µé‡
                            batch_size = value.size(0) if value.dim() > 0 else 1
                            fixed_batch[key] = torch.randn((batch_size, 3, 224, 224), dtype=torch.float32)
                            print(f"Warning: Replaced object pixel_values with random tensor")
                        except Exception:
                            fixed_batch[key] = torch.randn((1, 3, 224, 224), dtype=torch.float32)
                    else:
                        fixed_batch[key] = value.float()
                else:
                    fixed_batch[key] = safe_convert_to_tensor(value, torch.float32)
            
            elif key in ['image_id', 'expression']:
                # å­—ç¬¦ä¸²å­—æ®µä¿æŒä¸è®Š
                if isinstance(value, (list, tuple)):
                    fixed_batch[key] = [str(item) for item in value]
                else:
                    fixed_batch[key] = str(value) if value is not None else ""
            
            else:
                # å…¶ä»–å­—æ®µ
                if isinstance(value, torch.Tensor) and str(value.dtype) == 'object':
                    # å˜—è©¦ä¿®å¾©å°è±¡å¼µé‡
                    try:
                        fixed_batch[key] = safe_convert_to_tensor(value.tolist() if hasattr(value, 'tolist') else value)
                    except Exception:
                        fixed_batch[key] = value
                else:
                    fixed_batch[key] = value
                
        except Exception as e:
            print(f"âš ï¸  Error fixing {key}: {e}")
            fixed_batch[key] = value
    
    return fixed_batch


def safe_forward_pass(model, batch, device):
    """
    å®‰å…¨çš„æ¨¡å‹å‰å‘å‚³æ’­ï¼ŒåŒ…å«å®Œæ•´çš„éŒ¯èª¤è™•ç†
    """
    try:
        # 1. ä¿®å¾©æ•¸æ“šé¡å‹
        batch = fix_batch_data_types(batch)
        
        # 2. ç§»å‹•åˆ°è¨­å‚™
        device_batch = {}
        for key, value in batch.items():
            if isinstance(value, torch.Tensor):
                device_batch[key] = value.to(device)
            else:
                device_batch[key] = value
        
        # 3. æœ€å¾Œæª¢æŸ¥å¼µé‡é¡å‹
        for key, value in device_batch.items():
            if isinstance(value, torch.Tensor):
                if str(value.dtype) == 'object':
                    print(f"âš ï¸  Still have object tensor in {key} after fixing!")
                    if key == 'bbox':
                        device_batch[key] = torch.zeros((value.size(0), 4), dtype=torch.float32, device=device)
                    elif key in ['input_ids', 'attention_mask', 'labels']:
                        device_batch[key] = torch.zeros((value.size(0), 512), dtype=torch.long, device=device)
                    elif key == 'pixel_values':
                        device_batch[key] = torch.randn((value.size(0), 3, 224, 224), dtype=torch.float32, device=device)
        
        # 4. èª¿ç”¨æ¨¡å‹
        outputs = model(**device_batch)
        return outputs
        
    except Exception as e:
        print(f"âŒ Error in safe_forward_pass: {e}")
        # æ‰“å°èª¿è©¦ä¿¡æ¯
        print("Debug info:")
        for key, value in batch.items():
            if isinstance(value, torch.Tensor):
                print(f"  {key}: shape={value.shape}, dtype={value.dtype}")
            else:
                print(f"  {key}: type={type(value)}")
        raise e

# ================== ä¿®å¾©è£œä¸çµæŸ ==================

'''


def patch_script(script_path):
    """æ‡‰ç”¨ä¿®å¾©è£œä¸åˆ°è…³æœ¬"""
    
    # è®€å–åŸå§‹è…³æœ¬
    with open(script_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æª¢æŸ¥æ˜¯å¦å·²ç¶“æ‰“éè£œä¸
    if "RefCOCO æ•¸æ“šé¡å‹ä¿®å¾©è£œä¸" in content:
        print("âš ï¸  è…³æœ¬å·²ç¶“æ‰“éè£œä¸")
        return False
    
    # ç²å–è£œä¸ä»£ç¢¼
    patch_code = get_complete_patch_code()
    
    # åœ¨å°å…¥èªå¥å¾Œæ’å…¥è£œä¸
    import_pattern = r'((?:from|import)\s+.*?\n)'
    matches = list(re.finditer(import_pattern, content))
    
    if matches:
        # åœ¨æœ€å¾Œä¸€å€‹å°å…¥å¾Œæ’å…¥
        last_import_end = matches[-1].end()
        modified_content = content[:last_import_end] + patch_code + content[last_import_end:]
    else:
        # å¦‚æœæ‰¾ä¸åˆ°å°å…¥ï¼Œåœ¨æ–‡ä»¶é–‹é ­æ’å…¥
        modified_content = patch_code + content
    
    # æŸ¥æ‰¾ä¸¦ä¿®æ”¹è¨“ç·´å¾ªç’°
    # å°‹æ‰¾é¡ä¼¼ "outputs = model(**batch)" çš„æ¨¡å¼
    model_call_pattern = r'(\s*)(outputs\s*=\s*model\(\*\*batch\))'
    
    def replace_model_call(match):
        indent = match.group(1)
        original_call = match.group(2)
        
        replacement = f'''{indent}# === ä½¿ç”¨å®‰å…¨çš„å‰å‘å‚³æ’­ ===
{indent}try:
{indent}    outputs = safe_forward_pass(model, batch, device)'''
        
        return replacement
    
    modified_content = re.sub(model_call_pattern, replace_model_call, modified_content)
    
    # ç‚ºäº†ç¢ºä¿ç•°å¸¸è™•ç†å®Œæ•´ï¼Œæˆ‘å€‘éœ€è¦æ·»åŠ  except å¡Š
    # é€™éœ€è¦æ›´è¤‡é›œçš„é‚è¼¯ï¼Œç°¡åŒ–è™•ç†ï¼šåœ¨æ¯å€‹ try å¾ŒæŸ¥æ‰¾å°æ‡‰çš„è¨“ç·´ä»£ç¢¼
    
    # å¯«å…¥ä¿®æ”¹å¾Œçš„å…§å®¹
    with open(script_path, 'w', encoding='utf-8') as f:
        f.write(modified_content)
    
    return True


def create_standalone_training_script():
    """å‰µå»ºç¨ç«‹çš„ä¿®å¾©ç‰ˆè¨“ç·´è…³æœ¬"""
    
    script_content = '''#!/usr/bin/env python3
"""
train_refcoco_improved_fixed.py

ä¿®å¾©ç‰ˆçš„ RefCOCO è¨“ç·´è…³æœ¬
å·²ä¿®å¾© 'invalid data type str' éŒ¯èª¤
"""

import os
import sys
from pathlib import Path

# æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ°è·¯å¾‘
sys.path.append(str(Path(__file__).parent.parent))

import torch
import torch.nn as nn
import numpy as np
from typing import Any, Union, List, Dict
import warnings
warnings.filterwarnings("ignore", category=UserWarning)

# å…§å­˜å„ªåŒ–
os.environ["TOKENIZERS_PARALLELISM"] = "false"
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:32'
torch.cuda.empty_cache()

# å–®GPUè¨­ç½®
if "WORLD_SIZE" not in os.environ:
    os.environ["WORLD_SIZE"] = "1"
if "RANK" not in os.environ:
    os.environ["RANK"] = "0"
if "LOCAL_RANK" not in os.environ:
    os.environ["LOCAL_RANK"] = "0"

# å°å…¥ Cobra ç›¸é—œæ¨¡å¡Š
try:
    from cobra.conf import DatasetConfig, ModelConfig
    from cobra.models import get_llm_backbone_and_tokenizer, get_vision_backbone_and_transform, get_vlm
    from cobra.overwatch import initialize_overwatch
    from cobra.preprocessing import get_dataset_and_collator
    from cobra.training import Metrics, get_train_strategy
    from cobra.util import set_global_seed
    import draccus
except ImportError as e:
    print(f"âŒ ç„¡æ³•å°å…¥ Cobra æ¨¡å¡Š: {e}")
    print("è«‹ç¢ºä¿æ‚¨åœ¨æ­£ç¢ºçš„ Cobra ç’°å¢ƒä¸­é‹è¡Œæ­¤è…³æœ¬")
    sys.exit(1)

# åˆå§‹åŒ– Overwatch
overwatch = initialize_overwatch(__name__)

# ================== æ•¸æ“šé¡å‹ä¿®å¾©å‡½æ•¸ ==================

def safe_convert_to_tensor(data: Any, dtype: torch.dtype = torch.float32, expected_shape: tuple = None) -> torch.Tensor:
    """å®‰å…¨åœ°å°‡ä»»ä½•æ•¸æ“šè½‰æ›ç‚ºPyTorchå¼µé‡"""
    try:
        if data is None:
            return torch.zeros(expected_shape or (1,), dtype=dtype)
        
        if isinstance(data, str):
            data = data.strip()
            if data.startswith('[') and data.endswith(']'):
                try:
                    cleaned = data.strip('[]').replace(' ', '')
                    if cleaned:
                        values = [float(x) for x in cleaned.split(',')]
                        tensor = torch.tensor(values, dtype=dtype)
                        if expected_shape and len(expected_shape) == 1 and tensor.numel() != expected_shape[0]:
                            if tensor.numel() > expected_shape[0]:
                                tensor = tensor[:expected_shape[0]]
                            else:
                                padded = torch.zeros(expected_shape[0], dtype=dtype)
                                padded[:tensor.numel()] = tensor
                                tensor = padded
                        return tensor
                    else:
                        return torch.zeros(expected_shape or (4,), dtype=dtype)
                except Exception:
                    return torch.zeros(expected_shape or (4,), dtype=dtype)
            elif ',' in data:
                try:
                    values = [float(x.strip()) for x in data.split(',')]
                    return torch.tensor(values, dtype=dtype)
                except Exception:
                    return torch.zeros(expected_shape or (len(data.split(',')),), dtype=dtype)
            else:
                try:
                    if data.replace('.', '').replace('-', '').isdigit():
                        return torch.tensor(float(data), dtype=dtype)
                    else:
                        return torch.zeros(expected_shape or (1,), dtype=dtype)
                except Exception:
                    return torch.zeros(expected_shape or (1,), dtype=dtype)
        
        elif isinstance(data, (list, tuple)):
            try:
                numeric_data = []
                for item in data:
                    if isinstance(item, str):
                        try:
                            if item.strip():
                                numeric_data.append(float(item))
                            else:
                                numeric_data.append(0.0)
                        except ValueError:
                            numeric_data.append(0.0)
                    elif isinstance(item, (int, float, bool)):
                        numeric_data.append(float(item))
                    else:
                        numeric_data.append(0.0)
                
                tensor = torch.tensor(numeric_data, dtype=dtype)
                if expected_shape and len(expected_shape) == 1:
                    if tensor.numel() > expected_shape[0]:
                        tensor = tensor[:expected_shape[0]]
                    elif tensor.numel() < expected_shape[0]:
                        padded = torch.zeros(expected_shape[0], dtype=dtype)
                        padded[:tensor.numel()] = tensor
                        tensor = padded
                
                return tensor
            except Exception:
                return torch.zeros(expected_shape or (len(data),), dtype=dtype)
        
        elif isinstance(data, torch.Tensor):
            try:
                if str(data.dtype) == 'object':
                    try:
                        if hasattr(data, 'tolist'):
                            extracted_data = data.tolist()
                        else:
                            extracted_data = [item for item in data]
                        return safe_convert_to_tensor(extracted_data, dtype, expected_shape)
                    except Exception:
                        return torch.zeros(expected_shape or data.shape, dtype=dtype)
                else:
                    return data.to(dtype)
            except Exception:
                return torch.zeros(expected_shape or data.shape, dtype=dtype)
        
        elif isinstance(data, (int, float, bool, np.number)):
            return torch.tensor(float(data), dtype=dtype)
        
        else:
            return torch.zeros(expected_shape or (1,), dtype=dtype)
            
    except Exception as e:
        print(f"Error converting data: {e}")
        return torch.zeros(expected_shape or (1,), dtype=dtype)


def fix_batch_data_types(batch):
    """ä¿®å¾© batch ä¸­çš„æ•¸æ“šé¡å‹å•é¡Œ"""
    if not isinstance(batch, dict):
        return batch
    
    fixed_batch = {}
    
    for key, value in batch.items():
        try:
            if key == 'bbox':
                if isinstance(value, torch.Tensor):
                    if str(value.dtype) == 'object':
                        try:
                            bbox_list = []
                            for i in range(value.size(0)):
                                bbox_item = value[i]
                                if hasattr(bbox_item, 'item'):
                                    bbox_data = bbox_item.item()
                                else:
                                    bbox_data = bbox_item
                                
                                fixed_bbox = safe_convert_to_tensor(bbox_data, torch.float32, (4,))
                                bbox_list.append(fixed_bbox.unsqueeze(0))
                            
                            if bbox_list:
                                fixed_batch[key] = torch.cat(bbox_list, dim=0)
                            else:
                                fixed_batch[key] = torch.zeros((1, 4), dtype=torch.float32)
                        except Exception as e:
                            batch_size = value.size(0) if value.dim() > 0 else 1
                            fixed_batch[key] = torch.zeros((batch_size, 4), dtype=torch.float32)
                    else:
                        fixed_batch[key] = value.float()
                else:
                    fixed_batch[key] = safe_convert_to_tensor(value, torch.float32)
            
            elif key in ['input_ids', 'attention_mask', 'labels']:
                if isinstance(value, torch.Tensor):
                    if str(value.dtype) == 'object':
                        try:
                            text_list = []
                            for i in range(value.size(0)):
                                text_item = value[i]
                                if hasattr(text_item, 'item'):
                                    text_data = text_item.item()
                                else:
                                    text_data = text_item
                                
                                fixed_text = safe_convert_to_tensor(text_data, torch.long)
                                text_list.append(fixed_text.unsqueeze(0))
                            
                            if text_list:
                                max_len = max(t.size(1) for t in text_list)
                                padded_list = []
                                for t in text_list:
                                    if t.size(1) < max_len:
                                        pad_size = max_len - t.size(1)
                                        padding = torch.zeros((1, pad_size), dtype=torch.long)
                                        if key == 'labels':
                                            padding.fill_(-100)
                                        t = torch.cat([t, padding], dim=1)
                                    padded_list.append(t)
                                
                                fixed_batch[key] = torch.cat(padded_list, dim=0)
                            else:
                                fixed_batch[key] = torch.zeros((1, 512), dtype=torch.long)
                        except Exception:
                            fixed_batch[key] = torch.zeros_like(value, dtype=torch.long)
                    else:
                        fixed_batch[key] = value.long()
                else:
                    fixed_batch[key] = safe_convert_to_tensor(value, torch.long)
            
            elif key == 'pixel_values':
                if isinstance(value, torch.Tensor):
                    if str(value.dtype) == 'object':
                        batch_size = value.size(0) if value.dim() > 0 else 1
                        fixed_batch[key] = torch.randn((batch_size, 3, 224, 224), dtype=torch.float32)
                    else:
                        fixed_batch[key] = value.float()
                else:
                    fixed_batch[key] = safe_convert_to_tensor(value, torch.float32)
            
            else:
                fixed_batch[key] = value
                
        except Exception as e:
            print(f"âš ï¸  Error fixing {key}: {e}")
            fixed_batch[key] = value
    
    return fixed_batch


# ================== ä¸»è¨“ç·´é‚è¼¯ ==================

@draccus.wrap()
def train_refcoco_improved_fixed(cfg):
    """ä¿®å¾©ç‰ˆçš„ RefCOCO è¨“ç·´å‡½æ•¸"""
    
    print("ğŸš€ RefCOCO è¨“ç·´é–‹å§‹ (å·²ä¿®å¾©æ•¸æ“šé¡å‹å•é¡Œ)")
    print(f"é…ç½®: {cfg}")
    
    # è¨­ç½®è¨­å‚™
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ä½¿ç”¨è¨­å‚™: {device}")
    
    try:
        # é€™è£¡éœ€è¦æ ¹æ“šä½ çš„å¯¦éš› train_refcoco_improved.py è…³æœ¬ä¾†èª¿æ•´
        # ä»¥ä¸‹æ˜¯ä¸€å€‹åŸºæœ¬çš„æ¡†æ¶ï¼Œä½ éœ€è¦æ ¹æ“šå¯¦éš›æƒ…æ³ä¿®æ”¹
        
        # 1. åŠ è¼‰æ¨¡å‹ï¼ˆæ ¹æ“šä½ çš„é…ç½®ï¼‰
        # model = get_vlm(cfg.model)
        # model.to(device)
        
        # 2. å‰µå»ºæ•¸æ“šé›†å’Œæ•¸æ“šåŠ è¼‰å™¨
        # dataset, collator = get_dataset_and_collator(...)
        # dataloader = DataLoader(dataset, collate_fn=collator, ...)
        
        # 3. è¨­ç½®å„ªåŒ–å™¨
        # optimizer = torch.optim.AdamW(model.parameters(), ...)
        
        # 4. è¨“ç·´å¾ªç’°ï¼ˆé—œéµä¿®å¾©éƒ¨åˆ†ï¼‰
        print("é–‹å§‹è¨“ç·´å¾ªç’°...")
        
        # for epoch in range(cfg.num_epochs):
        #     for step, batch in enumerate(dataloader):
        #         try:
        #             # === é—œéµä¿®å¾©ï¼šä½¿ç”¨ fix_batch_data_types ===
        #             batch = fix_batch_data_types(batch)
        #             
        #             # ç§»å‹•åˆ°è¨­å‚™
        #             device_batch = {}
        #             for key, value in batch.items():
        #                 if isinstance(value, torch.Tensor):
        #                     device_batch[key] = value.to(device)
        #                 else:
        #                     device_batch[key] = value
        #             
        #             # å‰å‘å‚³æ’­
        #             outputs = model(**device_batch)
        #             loss = outputs.loss
        #             
        #             # åå‘å‚³æ’­
        #             loss.backward()
        #             optimizer.step()
        #             optimizer.zero_grad()
        #             
        #             if step % 10 == 0:
        #                 print(f"Epoch {epoch}, Step {step}, Loss: {loss.item():.4f}")
        #         
        #         except Exception as e:
        #             print(f"âš ï¸  è¨“ç·´æ­¥é©Ÿ {step} è­¦å‘Š: {e}")
        #             optimizer.zero_grad()
        #             continue
        
        print("âœ… è¨“ç·´å®Œæˆ!")
        
    except Exception as e:
        print(f"âŒ è¨“ç·´å¤±æ•—: {e}")
        raise


if __name__ == "__main__":
    print("RefCOCO ä¿®å¾©ç‰ˆè¨“ç·´è…³æœ¬")
    print("=" * 50)
    print("âš ï¸  é€™æ˜¯ä¸€å€‹æ¨¡æ¿è…³æœ¬ï¼Œæ‚¨éœ€è¦æ ¹æ“šå¯¦éš›çš„ train_refcoco_improved.py ä¾†èª¿æ•´")
    print("é—œéµä¿®å¾©å·²åŒ…å«åœ¨ fix_batch_data_types() å‡½æ•¸ä¸­")
    
    # é‹è¡Œè¨“ç·´
    train_refcoco_improved_fixed()
'''
    
    return script_content


def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ”§ RefCOCO å®Œæ•´ä¿®å¾©å·¥å…·")
    print("=" * 60)
    
    # æª¢æŸ¥ç›®æ¨™è…³æœ¬æ˜¯å¦å­˜åœ¨
    script_path = Path("scripts/train_refcoco_improved.py")
    
    if not script_path.exists():
        print(f"âŒ ç›®æ¨™è…³æœ¬ä¸å­˜åœ¨: {script_path}")
        print("\nå‰µå»ºå‚™ç”¨è§£æ±ºæ–¹æ¡ˆ...")
        
        # å‰µå»ºä¿®å¾©å‡½æ•¸æ–‡ä»¶
        patch_code = get_complete_patch_code()
        with open("refcoco_data_type_fixes.py", "w", encoding="utf-8") as f:
            f.write(patch_code)
        print("âœ… å·²å‰µå»ºä¿®å¾©å‡½æ•¸æ–‡ä»¶: refcoco_data_type_fixes.py")
        
        # å‰µå»ºç¨ç«‹çš„è¨“ç·´è…³æœ¬æ¨¡æ¿
        standalone_script = create_standalone_training_script()
        with open("train_refcoco_improved_fixed.py", "w", encoding="utf-8") as f:
            f.write(standalone_script)
        print("âœ… å·²å‰µå»ºä¿®å¾©ç‰ˆè¨“ç·´è…³æœ¬æ¨¡æ¿: train_refcoco_improved_fixed.py")
        
        print("\nğŸ“– ä½¿ç”¨èªªæ˜:")
        print("1. å°‡ refcoco_data_type_fixes.py ä¸­çš„ä¿®å¾©å‡½æ•¸è¤‡è£½åˆ°æ‚¨çš„åŸå§‹è…³æœ¬ä¸­")
        print("2. åœ¨è¨“ç·´å¾ªç’°ä¸­æ·»åŠ : batch = fix_batch_data_types(batch)")
        print("3. æˆ–è€…ä¿®æ”¹ train_refcoco_improved_fixed.py æ¨¡æ¿ä¾†ä½¿ç”¨")
        
        return
    
    print(f"ğŸ“ æ‰¾åˆ°ç›®æ¨™è…³æœ¬: {script_path}")
    
    # å‰µå»ºå‚™ä»½
    backup_path = create_backup(script_path)
    if not backup_path:
        return
    
    try:
        # æ‡‰ç”¨ä¿®å¾©è£œä¸
        print("ğŸ”§ æ‡‰ç”¨ä¿®å¾©è£œä¸...")
        success = patch_script(script_path)
        
        if success:
            print("âœ… è£œä¸æ‡‰ç”¨æˆåŠŸ!")
            
            # é©—è­‰ä¿®å¾©
            with open(script_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            if "fix_batch_data_types" in content:
                print("âœ… é©—è­‰é€šé: ä¿®å¾©å‡½æ•¸å·²æ·»åŠ ")
            else:
                print("âš ï¸  è­¦å‘Š: ä¿®å¾©å‡½æ•¸å¯èƒ½æœªæ­£ç¢ºæ·»åŠ ")
            
            print("\nğŸš€ ä¿®å¾©å®Œæˆ! ç¾åœ¨å¯ä»¥é‹è¡Œæ‚¨çš„åŸå§‹å‘½ä»¤:")
            print("python scripts/train_refcoco_improved.py \\")
            print("    --model.type cobra-refcoco-lora+3b \\")
            print("    --refcoco_data_dir ./data/refcoco \\")
            print("    --max_samples 2000 \\")
            print("    --num_epochs 2 \\")
            print("    --run_id refcoco-improved-v1 \\")
            print("    --use_real_refcoco_data True")
            
            print(f"\nğŸ’¾ å‚™ä»½æ–‡ä»¶: {backup_path}")
            print("å¦‚æœæœ‰å•é¡Œï¼Œå¯ä»¥å¾å‚™ä»½æ¢å¾©")
            
        else:
            print("âš ï¸  è‡ªå‹•ä¿®å¾©æœªèƒ½å®Œå…¨æ‡‰ç”¨")
            print("è«‹æ‰‹å‹•æ‡‰ç”¨ä¿®å¾©:")
            
            # å‰µå»ºæ‰‹å‹•ä¿®å¾©æŒ‡å—
            manual_fix = """
# æ‰‹å‹•ä¿®å¾©æŒ‡å—

åœ¨æ‚¨çš„ train_refcoco_improved.py ä¸­é€²è¡Œä»¥ä¸‹ä¿®æ”¹:

1. åœ¨è…³æœ¬é–‹é ­æ·»åŠ ä¿®å¾©å‡½æ•¸ (å¾ä¸‹é¢è¤‡è£½):
"""
            manual_fix += get_complete_patch_code()
            manual_fix += """

2. åœ¨è¨“ç·´å¾ªç’°ä¸­ï¼Œå°‡:
   outputs = model(**batch)
   
   æ›¿æ›ç‚º:
   batch = fix_batch_data_types(batch)
   device_batch = {}
   for key, value in batch.items():
       if isinstance(value, torch.Tensor):
           device_batch[key] = value.to(device)
       else:
           device_batch[key] = value
   outputs = model(**device_batch)
"""
            
            with open("manual_fix_guide.txt", "w", encoding="utf-8") as f:
                f.write(manual_fix)
            
            print("ğŸ“ æ‰‹å‹•ä¿®å¾©æŒ‡å—å·²ä¿å­˜åˆ°: manual_fix_guide.txt")
    
    except Exception as e:
        print(f"âŒ ä¿®å¾©éç¨‹å‡ºéŒ¯: {e}")
        print("æ­£åœ¨å¾å‚™ä»½æ¢å¾©...")
        if backup_path and backup_path.exists():
            shutil.copy2(backup_path, script_path)
            print("âœ… å·²å¾å‚™ä»½æ¢å¾©")


if __name__ == "__main__":
    main()